// YAPL Code Generator - Main Code Generation Logic
// Translates IR to WUT-4 assembly

package main

import (
	"fmt"
	"strconv"
	"strings"
)

// CodeGen holds state for code generation
type CodeGen struct {
	prog *IRProgram
	emit *Emitter

	// Current function state
	currFunc *IRFunction

	// Saved register offsets within the frame
	savedRegOffsets map[int]int

	// Parameter stack offsets (for saving register params r1-r3)
	paramOffsets map[int]int
	numRegParams int // number of parameters passed in registers (0-3)

	// Whether current function makes calls (needs to save LINK)
	hasCalls   bool
	linkOffset int // stack offset where LINK is saved

	// Total frame size including saved registers and virtual register spill slots
	totalFrameSize int

	// Virtual register to stack offset mapping
	virtRegSlots map[string]int
	nextVirtSlot int

	// Pending arguments for function calls
	pendingArgs map[int]string

	// Whether this is a bootstrap program (no .code/.data directives)
	isBootstrap bool
}

// NewCodeGen creates a new code generator
func NewCodeGen(prog *IRProgram, emit *Emitter) *CodeGen {
	return &CodeGen{
		prog: prog,
		emit: emit,
	}
}

// Generate generates assembly for the entire program
func (cg *CodeGen) Generate() {
	// Header comment
	cg.emit.Comment("Generated by YAPL compiler Pass 4")
	cg.emit.Comment("Source: %s", cg.prog.SourceFile)
	cg.emit.BlankLine()

	// Check if this is a bootstrap program
	cg.isBootstrap = false
	for _, asm := range cg.prog.AsmDecls {
		if strings.Contains(asm, ".bootstrap") {
			cg.isBootstrap = true
			break
		}
	}

	// Emit file-level inline assembly (but filter out .bootstrap which is just a signal)
	for _, asm := range cg.prog.AsmDecls {
		if strings.Contains(asm, ".bootstrap") {
			continue // .bootstrap is not a real assembler directive
		}
		// Emit without indentation since these are usually directives
		fmt.Fprintln(cg.emit.out, asm)
	}
	if len(cg.prog.AsmDecls) > 0 {
		cg.emit.BlankLine()
	}

	// Generate code section - but not for bootstrap programs
	if !cg.isBootstrap {
		cg.emit.DataCode()
		cg.emit.BlankLine()
	}

	// For bootstrap programs, emit startup code at the very beginning
	// This initializes the stack pointer and calls main
	if cg.isBootstrap {
		cg.emit.Comment("Bootstrap startup code")
		cg.emit.Comment("Stack initialized to 0x1000 (top of page 0)")
		cg.emit.Label("_start")
		cg.emit.Ldi(R7, 0x1000)
		cg.emit.Jal("main")
		cg.emit.Instr0("hlt")
		cg.emit.BlankLine()
	}

	// Emit runtime library if needed
	cg.genRuntimeLibrary()

	// Generate all functions
	for _, f := range cg.prog.Functions {
		cg.genFunction(f)
	}

	// Generate data section
	cg.genDataSection()
}

// genRuntimeLibrary emits the runtime library functions needed by the program
func (cg *CodeGen) genRuntimeLibrary() {
	// Scan functions for runtime library calls
	needShru := false
	needShrs := false
	needShlu := false
	needMul := false
	needDivs := false
	needDivu := false
	needMods := false
	needModu := false

	for _, f := range cg.prog.Functions {
		for _, instr := range f.Instrs {
			switch instr.Op {
			case OpShrW:
				// Variable shifts need runtime
				if len(instr.Args) > 1 && !cg.isConstant(instr.Args[1]) {
					needShru = true
				}
			case OpSarW:
				if len(instr.Args) > 1 && !cg.isConstant(instr.Args[1]) {
					needShrs = true
				}
			case OpShlW:
				if len(instr.Args) > 1 && !cg.isConstant(instr.Args[1]) {
					needShlu = true
				}
			case OpMulW:
				needMul = true
			case OpDivS:
				needDivs = true
			case OpDivU:
				needDivu = true
			case OpModS:
				needMods = true
			case OpModU:
				needModu = true
			}
		}
	}

	if !needShru && !needShrs && !needShlu && !needMul && !needDivs && !needDivu && !needMods && !needModu {
		return
	}

	cg.emit.Comment("Runtime library for YAPL")
	cg.emit.BlankLine()

	if needShru {
		cg.emit.Label("__shru16")
		cg.emit.Comment("Shift R1 right by R2 bits (logical)")
		cg.emit.Tst(R2, R2)
		cg.emit.Brz("L_shru_done")
		cg.emit.Label("L_shru_loop")
		cg.emit.Srl(R1)
		cg.emit.Adi(R2, R2, -1)
		cg.emit.Tst(R2, R2)
		cg.emit.Brnz("L_shru_loop")
		cg.emit.Label("L_shru_done")
		cg.emit.Ret()
		cg.emit.BlankLine()
	}

	if needShrs {
		cg.emit.Label("__shrs16")
		cg.emit.Comment("Shift R1 right by R2 bits (arithmetic)")
		cg.emit.Tst(R2, R2)
		cg.emit.Brz("L_shrs_done")
		cg.emit.Label("L_shrs_loop")
		cg.emit.Sra(R1)
		cg.emit.Adi(R2, R2, -1)
		cg.emit.Tst(R2, R2)
		cg.emit.Brnz("L_shrs_loop")
		cg.emit.Label("L_shrs_done")
		cg.emit.Ret()
		cg.emit.BlankLine()
	}

	if needShlu {
		cg.emit.Label("__shlu16")
		cg.emit.Comment("Shift R1 left by R2 bits")
		cg.emit.Tst(R2, R2)
		cg.emit.Brz("L_shlu_done")
		cg.emit.Label("L_shlu_loop")
		cg.emit.Sll(R1)
		cg.emit.Adi(R2, R2, -1)
		cg.emit.Tst(R2, R2)
		cg.emit.Brnz("L_shlu_loop")
		cg.emit.Label("L_shlu_done")
		cg.emit.Ret()
		cg.emit.BlankLine()
	}

	if needMul {
		cg.emit.Label("__mul16")
		cg.emit.Comment("Multiply R1 * R2 -> R1")
		cg.emit.Mv(R3, R1)     // R3 = multiplicand
		cg.emit.Ldi(R1, 0)     // R1 = result (accumulator)
		cg.emit.Label("L_mul_loop")
		cg.emit.Tst(R2, R2)
		cg.emit.Brz("L_mul_done")
		// Check if low bit of R2 is set
		cg.emit.Mv(R4, R2)
		cg.emit.Ldi(R5, 1)
		cg.emit.And(R4, R4, R5)
		cg.emit.Tst(R4, R4)
		cg.emit.Brz("L_mul_skip")
		cg.emit.Add(R1, R1, R3) // result += multiplicand
		cg.emit.Label("L_mul_skip")
		cg.emit.Sll(R3)         // multiplicand <<= 1
		cg.emit.Srl(R2)         // multiplier >>= 1
		cg.emit.Br("L_mul_loop")
		cg.emit.Label("L_mul_done")
		cg.emit.Ret()
		cg.emit.BlankLine()
	}

	if needDivu {
		cg.emit.Label("__divu16")
		cg.emit.Comment("Unsigned divide R1 / R2 -> R1 (quotient)")
		// Simple restoring division
		cg.emit.Ldi(R3, 0)      // R3 = quotient
		cg.emit.Ldi(R4, 0)      // R4 = remainder
		cg.emit.Ldi(R5, 16)     // R5 = bit counter
		cg.emit.Label("L_divu_loop")
		cg.emit.Sll(R4)         // remainder <<= 1
		// Get high bit of dividend into low bit of remainder
		cg.emit.Mv(R6, R1)
		cg.emit.Ldi(R0, 15)     // Actually need to shift right by 15
		// Shift R1 left, carry high bit
		cg.emit.Tst(R1, R1)
		cg.emit.Brslt("L_divu_setbit")
		cg.emit.Br("L_divu_nobit")
		cg.emit.Label("L_divu_setbit")
		cg.emit.Adi(R4, R4, 1)
		cg.emit.Label("L_divu_nobit")
		cg.emit.Sll(R1)         // dividend <<= 1
		cg.emit.Sll(R3)         // quotient <<= 1
		// if remainder >= divisor
		cg.emit.Tst(R4, R2)
		cg.emit.Brult("L_divu_next")
		cg.emit.Sub(R4, R4, R2) // remainder -= divisor
		cg.emit.Adi(R3, R3, 1)  // quotient |= 1
		cg.emit.Label("L_divu_next")
		cg.emit.Adi(R5, R5, -1)
		cg.emit.Tst(R5, R5)
		cg.emit.Brnz("L_divu_loop")
		cg.emit.Mv(R1, R3)      // return quotient
		cg.emit.Ret()
		cg.emit.BlankLine()
	}

	if needDivs {
		cg.emit.Label("__divs16")
		cg.emit.Comment("Signed divide R1 / R2 -> R1")
		// Handle signs, call unsigned, fix sign
		cg.emit.Ldi(R3, 0)      // R3 = sign flag
		cg.emit.Tst(R1, R1)
		cg.emit.Brsge("L_divs_pos1")
		cg.emit.Sub(R1, R0, R1) // negate R1
		cg.emit.Adi(R3, R3, 1)
		cg.emit.Label("L_divs_pos1")
		cg.emit.Tst(R2, R2)
		cg.emit.Brsge("L_divs_pos2")
		cg.emit.Sub(R2, R0, R2) // negate R2
		cg.emit.Adi(R3, R3, 1)
		cg.emit.Label("L_divs_pos2")
		cg.emit.Adi(R7, R7, -2)
		cg.emit.Stw(R3, R7, 0)  // save sign
		cg.emit.Jal("__divu16")
		cg.emit.Ldw(R3, R7, 0)
		cg.emit.Adi(R7, R7, 2)
		cg.emit.Ldi(R4, 1)
		cg.emit.And(R3, R3, R4)
		cg.emit.Tst(R3, R3)
		cg.emit.Brz("L_divs_done")
		cg.emit.Sub(R1, R0, R1) // negate result
		cg.emit.Label("L_divs_done")
		cg.emit.Ret()
		cg.emit.BlankLine()
	}

	if needModu {
		cg.emit.Label("__modu16")
		cg.emit.Comment("Unsigned modulo R1 %% R2 -> R1")
		cg.emit.Ldi(R4, 0)      // R4 = remainder
		cg.emit.Ldi(R5, 16)     // R5 = bit counter
		cg.emit.Label("L_modu_loop")
		cg.emit.Sll(R4)
		cg.emit.Tst(R1, R1)
		cg.emit.Brslt("L_modu_setbit")
		cg.emit.Br("L_modu_nobit")
		cg.emit.Label("L_modu_setbit")
		cg.emit.Adi(R4, R4, 1)
		cg.emit.Label("L_modu_nobit")
		cg.emit.Sll(R1)
		cg.emit.Tst(R4, R2)
		cg.emit.Brult("L_modu_next")
		cg.emit.Sub(R4, R4, R2)
		cg.emit.Label("L_modu_next")
		cg.emit.Adi(R5, R5, -1)
		cg.emit.Tst(R5, R5)
		cg.emit.Brnz("L_modu_loop")
		cg.emit.Mv(R1, R4)      // return remainder
		cg.emit.Ret()
		cg.emit.BlankLine()
	}

	if needMods {
		cg.emit.Label("__mods16")
		cg.emit.Comment("Signed modulo R1 %% R2 -> R1")
		cg.emit.Ldi(R3, 0)      // R3 = sign of dividend
		cg.emit.Tst(R1, R1)
		cg.emit.Brsge("L_mods_pos1")
		cg.emit.Sub(R1, R0, R1)
		cg.emit.Ldi(R3, 1)
		cg.emit.Label("L_mods_pos1")
		cg.emit.Tst(R2, R2)
		cg.emit.Brsge("L_mods_pos2")
		cg.emit.Sub(R2, R0, R2)
		cg.emit.Label("L_mods_pos2")
		cg.emit.Adi(R7, R7, -2)
		cg.emit.Stw(R3, R7, 0)
		cg.emit.Jal("__modu16")
		cg.emit.Ldw(R3, R7, 0)
		cg.emit.Adi(R7, R7, 2)
		cg.emit.Tst(R3, R3)
		cg.emit.Brz("L_mods_done")
		cg.emit.Sub(R1, R0, R1) // result has sign of dividend
		cg.emit.Label("L_mods_done")
		cg.emit.Ret()
		cg.emit.BlankLine()
	}
}

func (cg *CodeGen) genDataSection() {
	if len(cg.prog.Globals) == 0 && len(cg.prog.Constants) == 0 {
		return
	}

	cg.emit.BlankLine()
	// Don't emit .data directive for bootstrap programs
	if !cg.isBootstrap {
		cg.emit.DataSection()
	}
	cg.emit.Align(2)
	cg.emit.BlankLine()

	// Emit global variables
	for _, g := range cg.prog.Globals {
		cg.emit.Label(g.Name)
		if g.Init != "" {
			// Has initializer - emit based on type
			switch g.Type {
			case "BYTES", "STRING":
				cg.emit.Bytes(g.Init)
			case "WORDS":
				// Parse comma-separated words
				cg.emit.Raw(".words " + g.Init)
			case "WORD":
				// Single word
				cg.emit.Words(cg.parseValue(g.Init))
			default:
				// Default to bytes
				cg.emit.Bytes(g.Init)
			}
		} else {
			// Uninitialized - reserve space
			cg.emit.Space(g.Size)
		}
	}
}

func (cg *CodeGen) genFunction(f *IRFunction) {
	cg.currFunc = f
	cg.virtRegSlots = make(map[string]int)
	cg.pendingArgs = make(map[int]string)
	cg.paramOffsets = make(map[int]int)

	// Count virtual registers used to allocate spill space
	maxVirtReg := 0
	for _, instr := range f.Instrs {
		if instr.Dest != "" && strings.HasPrefix(instr.Dest, "t") {
			n := cg.parseVirtRegNum(instr.Dest)
			if n > maxVirtReg {
				maxVirtReg = n
			}
		}
	}

	// Calculate frame layout:
	// [SP+0 ... SP+frameSize-1] = locals from IR
	// [SP+frameSize ... SP+frameSize+virtRegSpace-1] = virtual register spill slots
	// [SP+frameSize+virtRegSpace ... SP+frameSize+virtRegSpace+paramSaveSpace-1] = saved register params
	// [SP+frameSize+virtRegSpace+paramSaveSpace ... ] = saved callee-saved registers
	virtRegSpace := (maxVirtReg + 1) * 2 // each virtual reg gets 2 bytes
	cg.nextVirtSlot = f.FrameSize        // virtual regs start after locals

	// Save register parameters (r1-r3) to stack so they survive function calls
	cg.numRegParams = len(f.Params)
	if cg.numRegParams > 3 {
		cg.numRegParams = 3
	}
	paramSaveSpace := cg.numRegParams * 2
	for i := 0; i < cg.numRegParams; i++ {
		cg.paramOffsets[i] = f.FrameSize + virtRegSpace + i*2
	}

	// Check if function makes calls - if so, need to save LINK
	cg.hasCalls = cg.functionHasCalls(f)
	linkSaveSpace := 0
	if cg.hasCalls {
		linkSaveSpace = 2
		cg.linkOffset = f.FrameSize + virtRegSpace + paramSaveSpace
	}

	savedRegSize := 6 // always save R4, R5, R6 to simplify
	cg.savedRegOffsets = map[int]int{
		R4: f.FrameSize + virtRegSpace + paramSaveSpace + linkSaveSpace,
		R5: f.FrameSize + virtRegSpace + paramSaveSpace + linkSaveSpace + 2,
		R6: f.FrameSize + virtRegSpace + paramSaveSpace + linkSaveSpace + 4,
	}
	cg.totalFrameSize = f.FrameSize + virtRegSpace + paramSaveSpace + linkSaveSpace + savedRegSize

	cg.emit.Comment("Function: %s", f.Name)
	cg.emit.Comment("Visibility: %s, Return: %s", f.Visibility, f.ReturnType)
	cg.emit.Comment("Params: %d, Frame: %d bytes (locals=%d, virtregs=%d, params=%d, saved=%d)",
		len(f.Params), cg.totalFrameSize, f.FrameSize, virtRegSpace, paramSaveSpace, savedRegSize)
	cg.emit.BlankLine()

	// Function label
	cg.emit.Label(f.Name)

	// Prologue
	cg.genPrologue()

	// Generate code for each instruction
	for _, instr := range f.Instrs {
		cg.genInstruction(instr)
	}

	// Epilogue label and code
	cg.emit.Label(fmt.Sprintf("L_%s_epilogue", f.Name))
	cg.genEpilogue()

	cg.emit.BlankLine()
}

func (cg *CodeGen) functionHasCalls(f *IRFunction) bool {
	for _, instr := range f.Instrs {
		if instr.Op == OpCall {
			return true
		}
	}
	return false
}

func (cg *CodeGen) genPrologue() {
	if cg.totalFrameSize > 0 {
		// For large frames, we need to save R4 before using it as scratch
		// Strategy: save R4 at [SP - offset] before adjusting SP
		if cg.totalFrameSize > 63 {
			// Pre-save R4 to its final location relative to current SP
			// After SP adjustment, R4's save slot will be at SP + savedRegOffsets[R4]
			// Before adjustment, that's SP - totalFrameSize + savedRegOffsets[R4]
			preSaveOffset := -cg.totalFrameSize + cg.savedRegOffsets[R4]
			if preSaveOffset >= -64 && preSaveOffset <= 63 {
				cg.emit.Stw(R4, R7, preSaveOffset)
			} else {
				// Very large frame - use R5 as scratch to compute address
				cg.emit.Ldi(R5, preSaveOffset)
				cg.emit.Add(R5, R7, R5)
				cg.emit.Stw(R4, R5, 0)
			}

			// Now use R4 to allocate frame
			cg.emit.Ldi(R4, cg.totalFrameSize)
			cg.emit.Sub(R7, R7, R4)

			// Save R5 and R6 (R4 is already saved)
			cg.emitStoreStack(R5, cg.savedRegOffsets[R5])
			cg.emitStoreStack(R6, cg.savedRegOffsets[R6])
		} else {
			// Small frame: simple case
			cg.emit.Adi(R7, R7, -cg.totalFrameSize)
			cg.emit.Stw(R4, R7, cg.savedRegOffsets[R4])
			cg.emit.Stw(R5, R7, cg.savedRegOffsets[R5])
			cg.emit.Stw(R6, R7, cg.savedRegOffsets[R6])
		}

		// Save register parameters (r1-r3) to stack so they survive function calls
		for i := 0; i < cg.numRegParams; i++ {
			cg.emit.Stw(R1+i, R7, cg.paramOffsets[i])
		}

		// Save LINK if this function makes calls (LINK is SPR 0)
		if cg.hasCalls {
			cg.emit.Lsp(R3, R0) // Load LINK into R3 (R0 contains 0, so SPR[0] = LINK)
			cg.emit.Stw(R3, R7, cg.linkOffset)
		}
	}
}

func (cg *CodeGen) genEpilogue() {
	if cg.totalFrameSize > 0 {
		if cg.totalFrameSize > 63 {
			// Large frame epilogue:
			// 1. Restore LINK if needed
			// 2. Restore R5 and R6 using R4 as scratch
			// 3. Load R4's saved value into R2 (temporary - R1 has return value)
			// 4. Deallocate frame using R4 as scratch
			// 5. Move R2 to R4

			// Restore LINK first if this function made calls
			if cg.hasCalls {
				cg.emitLoadStack(R3, cg.linkOffset)
				cg.emit.Ssp(R3, R0) // Store R3 into SPR[0] = LINK
			}

			// Restore R5 (use R4 as scratch for address if needed)
			cg.emitLoadStack(R5, cg.savedRegOffsets[R5])
			// Restore R6 (use R4 as scratch for address if needed)
			cg.emitLoadStack(R6, cg.savedRegOffsets[R6])

			// Load R4's saved value into R2 (temporary, preserves return value in R1)
			// Can't use emitLoadStack because it might clobber the dest register calculation
			r4Offset := cg.savedRegOffsets[R4]
			if r4Offset >= -64 && r4Offset <= 63 {
				cg.emit.Ldw(R2, R7, r4Offset)
			} else {
				cg.emit.Ldi(R4, r4Offset)
				cg.emit.Add(R4, R7, R4)
				cg.emit.Ldw(R2, R4, 0)
			}

			// Deallocate frame
			cg.emit.Ldi(R4, cg.totalFrameSize)
			cg.emit.Add(R7, R7, R4)

			// Restore R4 from temporary
			cg.emit.Mv(R4, R2)
		} else {
			// Small frame: simple case
			// Restore LINK first if this function made calls
			if cg.hasCalls {
				cg.emit.Ldw(R3, R7, cg.linkOffset)
				cg.emit.Ssp(R3, R0) // Store R3 into SPR[0] = LINK
			}
			cg.emit.Ldw(R4, R7, cg.savedRegOffsets[R4])
			cg.emit.Ldw(R5, R7, cg.savedRegOffsets[R5])
			cg.emit.Ldw(R6, R7, cg.savedRegOffsets[R6])
			cg.emit.Adi(R7, R7, cg.totalFrameSize)
		}
	}

	// Return
	cg.emit.Ret()
}

func (cg *CodeGen) genInstruction(instr *IRInstr) {
	switch instr.Op {
	case OpLabel:
		// Strip leading dot from label names (assembler requires labels start with a letter)
		label := instr.Label
		if strings.HasPrefix(label, ".") {
			label = "L_" + label[1:]
		}
		cg.emit.Label(label)

	case OpConstW, OpConstB:
		cg.genConst(instr)

	case OpLoadW, OpLoadB, OpLoadBU:
		cg.genLoad(instr)

	case OpStoreW, OpStoreB:
		cg.genStore(instr)

	case OpAddr:
		cg.genAddr(instr)

	case OpParam:
		cg.genParam(instr)

	case OpSetParam:
		cg.genSetParam(instr)

	case OpCopy:
		cg.genCopy(instr)

	case OpAddW:
		cg.genBinOp(instr, "add")

	case OpSubW:
		cg.genBinOp(instr, "sub")

	case OpMulW:
		cg.genMul(instr)

	case OpDivS, OpDivU, OpModS, OpModU:
		cg.genDivMod(instr)

	case OpNegW:
		cg.genNeg(instr)

	case OpAndW:
		cg.genBinOp(instr, "and")

	case OpOrW:
		cg.genBinOp(instr, "or")

	case OpXorW:
		cg.genBinOp(instr, "xor")

	case OpNotW:
		cg.genNot(instr)

	case OpShlW, OpShrW, OpSarW:
		cg.genShift(instr)

	case OpEqW, OpNeW, OpLtS, OpLeS, OpGtS, OpGeS, OpLtU, OpLeU, OpGtU, OpGeU:
		cg.genCompare(instr)

	case OpJump:
		cg.emit.Br(cg.fixLabel(instr.Target))

	case OpJumpZ:
		cg.genJumpZ(instr)

	case OpJumpNZ:
		cg.genJumpNZ(instr)

	case OpArg:
		cg.genArg(instr)

	case OpCall:
		cg.genCall(instr)

	case OpReturn:
		cg.genReturn(instr)

	case OpAsm:
		if len(instr.Args) > 0 {
			cg.emit.Raw(instr.Args[0])
		}
	}
}

// getVirtRegSlot returns the stack offset for a virtual register
func (cg *CodeGen) getVirtRegSlot(virt string) int {
	if offset, ok := cg.virtRegSlots[virt]; ok {
		return offset
	}
	// Allocate new slot
	n := cg.parseVirtRegNum(virt)
	offset := cg.currFunc.FrameSize + n*2
	cg.virtRegSlots[virt] = offset
	return offset
}

func (cg *CodeGen) parseVirtRegNum(virt string) int {
	if strings.HasPrefix(virt, "t") {
		n, _ := strconv.Atoi(virt[1:])
		return n
	}
	return 0
}

// loadVirtReg loads a virtual register into a physical register
func (cg *CodeGen) loadVirtReg(virt string, phys int) {
	offset := cg.getVirtRegSlot(virt)
	cg.emitLoadStack(phys, offset)
}

// storeVirtReg stores a physical register to a virtual register's stack slot
func (cg *CodeGen) storeVirtReg(phys int, virt string) {
	offset := cg.getVirtRegSlot(virt)
	cg.emitStoreStack(phys, offset)
}

// emitLoadStack loads from [SP+offset] into dest, handling large offsets
func (cg *CodeGen) emitLoadStack(dest int, offset int) {
	if offset >= -64 && offset <= 63 {
		cg.emit.Ldw(dest, R7, offset)
	} else {
		// Large offset: compute address first
		// Use dest register as scratch since we're loading into it anyway
		cg.emit.Ldi(dest, offset)
		cg.emit.Add(dest, R7, dest)
		cg.emit.Ldw(dest, dest, 0)
	}
}

// emitStoreStack stores src to [SP+offset], handling large offsets
// Uses R3 as scratch register for large offsets (caller must ensure R3 is available)
func (cg *CodeGen) emitStoreStack(src int, offset int) {
	if offset >= -64 && offset <= 63 {
		cg.emit.Stw(src, R7, offset)
	} else {
		// Large offset: compute address first
		// Need a scratch register - use R3 if src != R3, otherwise use R2
		scratch := R3
		if src == R3 {
			scratch = R2
		}
		cg.emit.Ldi(scratch, offset)
		cg.emit.Add(scratch, R7, scratch)
		cg.emit.Stw(src, scratch, 0)
	}
}

// loadOperand loads an operand into a physical register
// operand can be: virtual register (tN), constant (0xNNNN), SP, or label
func (cg *CodeGen) loadOperand(operand string, phys int) {
	operand = strings.TrimSpace(operand)

	// Virtual register
	if strings.HasPrefix(operand, "t") {
		cg.loadVirtReg(operand, phys)
		return
	}

	// Constant
	if cg.isConstant(operand) {
		cg.emit.Ldi(phys, cg.parseValue(operand))
		return
	}

	// SP
	if operand == "SP" {
		cg.emit.Mv(phys, R7)
		return
	}

	// Label (global address)
	cg.emit.LdiLabel(phys, operand)
}

func (cg *CodeGen) genConst(instr *IRInstr) {
	// dest = CONST.W value
	value := cg.parseValue(instr.Args[0])
	cg.emit.Ldi(R4, value)
	cg.storeVirtReg(R4, instr.Dest)
}

func (cg *CodeGen) genLoad(instr *IRInstr) {
	// dest = LOAD.W [addr]
	addr := instr.Args[0]

	if base, offset, ok := cg.parseStackAddr(addr); ok {
		// Stack-relative: [SP+n]
		if instr.Op == OpLoadW {
			cg.emit.Ldw(R4, base, offset)
		} else {
			cg.emit.Ldb(R4, base, offset)
			if instr.Op == OpLoadB {
				cg.emit.Sxt(R4)
			}
		}
	} else if reg, offset, ok := cg.parseRegAddr(addr); ok {
		// Register indirect: [tN] or [tN+offset]
		cg.loadVirtReg(reg, R5)
		if instr.Op == OpLoadW {
			cg.emit.Ldw(R4, R5, offset)
		} else {
			cg.emit.Ldb(R4, R5, offset)
			if instr.Op == OpLoadB {
				cg.emit.Sxt(R4)
			}
		}
	} else if label := cg.parseGlobalAddr(addr); label != "" {
		// Global: [label]
		cg.emit.LdiLabel(R5, label)
		if instr.Op == OpLoadW {
			cg.emit.Ldw(R4, R5, 0)
		} else {
			cg.emit.Ldb(R4, R5, 0)
			if instr.Op == OpLoadB {
				cg.emit.Sxt(R4)
			}
		}
	}

	cg.storeVirtReg(R4, instr.Dest)
}

func (cg *CodeGen) genStore(instr *IRInstr) {
	// STORE.W [addr], value
	addr := instr.Args[0]

	// Load value into R4
	cg.loadOperand(instr.Args[1], R4)

	if base, offset, ok := cg.parseStackAddr(addr); ok {
		// Stack-relative
		if instr.Op == OpStoreW {
			cg.emit.Stw(R4, base, offset)
		} else {
			cg.emit.Stb(R4, base, offset)
		}
	} else if reg, offset, ok := cg.parseRegAddr(addr); ok {
		// Register indirect - load address into R5
		cg.loadVirtReg(reg, R5)
		if instr.Op == OpStoreW {
			cg.emit.Stw(R4, R5, offset)
		} else {
			cg.emit.Stb(R4, R5, offset)
		}
	} else if label := cg.parseGlobalAddr(addr); label != "" {
		// Global: load address into R5
		cg.emit.LdiLabel(R5, label)
		if instr.Op == OpStoreW {
			cg.emit.Stw(R4, R5, 0)
		} else {
			cg.emit.Stb(R4, R5, 0)
		}
	}
}

func (cg *CodeGen) genAddr(instr *IRInstr) {
	// dest = ADDR label
	label := instr.Args[0]
	cg.emit.LdiLabel(R4, label)
	cg.storeVirtReg(R4, instr.Dest)
}

func (cg *CodeGen) genParam(instr *IRInstr) {
	// dest = PARAM n
	paramIndex := cg.parseValue(instr.Args[0])

	if paramIndex < 3 {
		// Parameter was passed in R1, R2, or R3 but saved to stack in prologue
		// Load from saved location so it survives function calls
		offset := cg.paramOffsets[paramIndex]
		cg.emitLoadStack(R4, offset)
	} else {
		// Parameter is on stack (passed by caller)
		// Stack args are at [SP + totalFrameSize + 2*(paramIndex-3) + 2]
		offset := cg.totalFrameSize + 2*(paramIndex-3) + 2
		cg.emit.Ldw(R4, R7, offset)
	}
	cg.storeVirtReg(R4, instr.Dest)
}

func (cg *CodeGen) genSetParam(instr *IRInstr) {
	// SETPARAM n, value - update a parameter's saved value
	paramIndex := cg.parseValue(instr.Args[0])
	cg.loadOperand(instr.Args[1], R4)

	if paramIndex < 3 {
		// Parameter was passed in R1, R2, or R3 but saved to stack
		// Write to the saved stack location
		offset := cg.paramOffsets[paramIndex]
		cg.emitStoreStack(R4, offset)
	} else {
		// Write to stack location (caller's stack area)
		offset := cg.totalFrameSize + 2*(paramIndex-3) + 2
		cg.emit.Stw(R4, R7, offset)
	}
}

func (cg *CodeGen) genCopy(instr *IRInstr) {
	// dest = COPY src
	cg.loadOperand(instr.Args[0], R4)
	cg.storeVirtReg(R4, instr.Dest)
}

func (cg *CodeGen) genBinOp(instr *IRInstr, op string) {
	// dest = OP a, b
	// Load left into R4, right into R5, result to R6, then store to dest
	cg.loadOperand(instr.Args[0], R4)
	cg.loadOperand(instr.Args[1], R5)

	switch op {
	case "add":
		cg.emit.Add(R6, R4, R5)
	case "sub":
		cg.emit.Sub(R6, R4, R5)
	case "and":
		cg.emit.And(R6, R4, R5)
	case "or":
		cg.emit.Or(R6, R4, R5)
	case "xor":
		cg.emit.Xor(R6, R4, R5)
	}

	cg.storeVirtReg(R6, instr.Dest)
}

func (cg *CodeGen) genMul(instr *IRInstr) {
	// dest = MUL.W a, b -> call __mul16
	cg.loadOperand(instr.Args[0], R1)
	cg.loadOperand(instr.Args[1], R2)

	// Call runtime function
	cg.emit.Jal("__mul16")

	// Result is in R1
	cg.storeVirtReg(R1, instr.Dest)
}

func (cg *CodeGen) genDivMod(instr *IRInstr) {
	// Similar to multiply - call runtime function
	cg.loadOperand(instr.Args[0], R1)
	cg.loadOperand(instr.Args[1], R2)

	// Select runtime function
	var rtFunc string
	switch instr.Op {
	case OpDivS:
		rtFunc = "__divs16"
	case OpDivU:
		rtFunc = "__divu16"
	case OpModS:
		rtFunc = "__mods16"
	case OpModU:
		rtFunc = "__modu16"
	}

	cg.emit.Jal(rtFunc)
	cg.storeVirtReg(R1, instr.Dest)
}

func (cg *CodeGen) genNeg(instr *IRInstr) {
	// dest = NEG.W a -> sub dest, r0, a
	cg.loadOperand(instr.Args[0], R4)
	cg.emit.Sub(R4, R0, R4)
	cg.storeVirtReg(R4, instr.Dest)
}

func (cg *CodeGen) genNot(instr *IRInstr) {
	// dest = NOT.W a
	cg.loadOperand(instr.Args[0], R4)
	cg.emit.Not(R4)
	cg.storeVirtReg(R4, instr.Dest)
}

func (cg *CodeGen) genShift(instr *IRInstr) {
	// dest = SHL.W/SHR.W/SAR.W a, b
	amount := instr.Args[1]

	// Check if shift amount is a constant
	if cg.isConstant(amount) {
		n := cg.parseValue(amount)
		cg.loadOperand(instr.Args[0], R4)
		// Unroll small constant shifts
		for i := 0; i < n && i < 16; i++ {
			switch instr.Op {
			case OpShlW:
				cg.emit.Sll(R4)
			case OpShrW:
				cg.emit.Srl(R4)
			case OpSarW:
				cg.emit.Sra(R4)
			}
		}
		cg.storeVirtReg(R4, instr.Dest)
	} else {
		// Variable shift - call runtime function
		cg.loadOperand(instr.Args[0], R1)
		cg.loadOperand(amount, R2)

		var rtFunc string
		switch instr.Op {
		case OpShlW:
			rtFunc = "__shlu16"
		case OpShrW:
			rtFunc = "__shru16"
		case OpSarW:
			rtFunc = "__shrs16"
		}
		cg.emit.Jal(rtFunc)
		cg.storeVirtReg(R1, instr.Dest)
	}
}

func (cg *CodeGen) genCompare(instr *IRInstr) {
	// dest = CMP a, b -> produces 0 or 1
	// IMPORTANT: ldi clobbers flags (uses lui+adi), so we must branch
	// immediately after tst, before setting any values.
	cg.loadOperand(instr.Args[0], R4)
	cg.loadOperand(instr.Args[1], R5)

	trueLabel := cg.emit.NewLabel("cmp_t")
	doneLabel := cg.emit.NewLabel("cmp_d")

	// Compare
	cg.emit.Tst(R4, R5)

	// Branch to true case if condition is met (must happen before ldi!)
	switch instr.Op {
	case OpEqW:
		cg.emit.Brz(trueLabel)
	case OpNeW:
		cg.emit.Brnz(trueLabel)
	case OpLtS:
		cg.emit.Brslt(trueLabel)
	case OpGeS:
		cg.emit.Brsge(trueLabel)
	case OpLtU:
		cg.emit.Brult(trueLabel)
	case OpGeU:
		cg.emit.Bruge(trueLabel)
	case OpLeS:
		// a <= b: true if a < b OR a == b
		cg.emit.Brslt(trueLabel)
		cg.emit.Brz(trueLabel)
	case OpGtS:
		// a > b: true if NOT (a <= b), i.e., NOT (a < b OR a == b)
		cg.emit.Brslt(doneLabel) // if a < b, false
		cg.emit.Brz(doneLabel)   // if a == b, false
		cg.emit.Br(trueLabel)    // otherwise true
	case OpLeU:
		cg.emit.Brult(trueLabel)
		cg.emit.Brz(trueLabel)
	case OpGtU:
		cg.emit.Brult(doneLabel) // if a < b, false
		cg.emit.Brz(doneLabel)   // if a == b, false
		cg.emit.Br(trueLabel)    // otherwise true
	}

	// Fall through: condition was false
	cg.emit.Ldi(R6, 0)
	cg.emit.Br(doneLabel)

	// True case
	cg.emit.Label(trueLabel)
	cg.emit.Ldi(R6, 1)

	cg.emit.Label(doneLabel)
	cg.storeVirtReg(R6, instr.Dest)
}

func (cg *CodeGen) genJumpZ(instr *IRInstr) {
	// JUMPZ cond, label
	cg.loadOperand(instr.Args[0], R4)
	// Use adi r4, r4, 0 to test if r4 is zero (sets Z flag correctly)
	// Note: tst r4, r4 computes r4-r4=0, which always sets Z=1!
	cg.emit.Adi(R4, R4, 0)
	cg.emit.Brz(cg.fixLabel(instr.Target))
}

func (cg *CodeGen) genJumpNZ(instr *IRInstr) {
	// JUMPNZ cond, label
	cg.loadOperand(instr.Args[0], R4)
	// Use adi r4, r4, 0 to test if r4 is zero (sets Z flag correctly)
	// Note: tst r4, r4 computes r4-r4=0, which always sets Z=1!
	cg.emit.Adi(R4, R4, 0)
	cg.emit.Brnz(cg.fixLabel(instr.Target))
}

func (cg *CodeGen) genArg(instr *IRInstr) {
	// ARG n, value - record for later CALL
	argIndex := cg.parseValue(instr.Args[0])
	cg.pendingArgs[argIndex] = instr.Args[1]
}

func (cg *CodeGen) genCall(instr *IRInstr) {
	// CALL func, nargs (or dest = CALL func, nargs)
	funcName := instr.Args[0]
	nargs := cg.parseValue(instr.Args[1])

	// Push stack arguments (args 3+) right-to-left
	stackArgCount := 0
	if nargs > 3 {
		stackArgCount = nargs - 3
		for i := nargs - 1; i >= 3; i-- {
			if argVirt, ok := cg.pendingArgs[i]; ok {
				cg.loadOperand(argVirt, R4)
				cg.emit.Adi(R7, R7, -2)
				cg.emit.Stw(R4, R7, 0)
			}
		}
	}

	// Load register arguments (args 0-2) into R1, R2, R3
	// Load in reverse order to avoid clobbering
	for i := min(nargs, 3) - 1; i >= 0; i-- {
		if argVirt, ok := cg.pendingArgs[i]; ok {
			destReg := R1 + i
			cg.loadOperand(argVirt, destReg)
		}
	}

	// Call
	cg.emit.Jal(funcName)

	// Clean up stack arguments
	if stackArgCount > 0 {
		cg.emit.Adi(R7, R7, stackArgCount*2)
	}

	// Store result if needed
	if instr.Dest != "" {
		cg.storeVirtReg(R1, instr.Dest)
	}

	// Clear pending args
	cg.pendingArgs = make(map[int]string)
}

func (cg *CodeGen) genReturn(instr *IRInstr) {
	// RETURN [value]
	if len(instr.Args) > 0 && instr.Args[0] != "" {
		cg.loadOperand(instr.Args[0], R1)
	}
	cg.emit.Br(fmt.Sprintf("L_%s_epilogue", cg.currFunc.Name))
}

// Helper functions

func (cg *CodeGen) parseValue(s string) int {
	s = strings.TrimSpace(s)
	v, _ := strconv.ParseInt(s, 0, 32)
	return int(v)
}

func (cg *CodeGen) parseStackAddr(addr string) (base int, offset int, ok bool) {
	// [SP+n]
	addr = strings.TrimSpace(addr)
	if !strings.HasPrefix(addr, "[SP+") || !strings.HasSuffix(addr, "]") {
		return 0, 0, false
	}
	inner := addr[4 : len(addr)-1]
	offset = cg.parseValue(inner)
	return R7, offset, true
}

func (cg *CodeGen) parseRegAddr(addr string) (reg string, offset int, ok bool) {
	// [tN] or [tN+n]
	addr = strings.TrimSpace(addr)
	if !strings.HasPrefix(addr, "[") || !strings.HasSuffix(addr, "]") {
		return "", 0, false
	}
	inner := addr[1 : len(addr)-1]

	// Check for virtual register
	if !strings.HasPrefix(inner, "t") {
		return "", 0, false
	}

	// Check for offset
	if idx := strings.Index(inner, "+"); idx > 0 {
		reg = inner[:idx]
		offset = cg.parseValue(inner[idx+1:])
	} else {
		reg = inner
		offset = 0
	}
	return reg, offset, true
}

func (cg *CodeGen) parseGlobalAddr(addr string) string {
	// [label]
	addr = strings.TrimSpace(addr)
	if !strings.HasPrefix(addr, "[") || !strings.HasSuffix(addr, "]") {
		return ""
	}
	inner := addr[1 : len(addr)-1]
	// If it's not SP+ or a virtual register, it's a label
	if strings.HasPrefix(inner, "SP+") || strings.HasPrefix(inner, "t") {
		return ""
	}
	return inner
}

func (cg *CodeGen) isConstant(s string) bool {
	s = strings.TrimSpace(s)
	if s == "" {
		return false
	}
	if strings.HasPrefix(s, "0x") || strings.HasPrefix(s, "0X") {
		return true
	}
	if s[0] == '-' || (s[0] >= '0' && s[0] <= '9') {
		return true
	}
	return false
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// fixLabel converts dot-prefixed labels to valid assembler labels
func (cg *CodeGen) fixLabel(label string) string {
	if strings.HasPrefix(label, ".") {
		return "L_" + label[1:]
	}
	return label
}
